{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import torch.nn.functional as F\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sparse2tensor(data):\n",
    "    return torch.FloatTensor(data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader():\n",
    "    '''\n",
    "    Load Movielens dataset\n",
    "    '''\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.pro_dir = os.path.join(path, 'pro_sg')\n",
    "        #error 설정\n",
    "        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n",
    "        # load_n_items 를 통해 이전에 저장해뒀던 아이템의 랜덤 순서 불러옴\n",
    "        self.n_items = self.load_n_items()\n",
    "    \n",
    "    def load_data(self, datatype='train'):\n",
    "        if datatype == 'train':\n",
    "            return self._load_train_data()\n",
    "        elif datatype == 'validation':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        elif datatype == 'test':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        elif datatype == 'sub':\n",
    "            return self._load_train_data(datatype)\n",
    "        else:\n",
    "            raise ValueError(\"datatype should be in [train, validation, test, submission]\")\n",
    "    \n",
    "    # self.n_items 에 이전에 저장해뒀던 아이템의 랜덤순서 가져다주는 함수\n",
    "    def load_n_items(self):\n",
    "        unique_sid = list()\n",
    "        with open(os.path.join(self.pro_dir, 'unique_sub_sid.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                unique_sid.append(line.strip())\n",
    "        n_items = len(unique_sid)\n",
    "        return n_items\n",
    "    \n",
    "    def _load_train_data(self, datatype = 'train'):\n",
    "        path = os.path.join(self.pro_dir, f'{datatype}.csv')\n",
    "        \n",
    "        tp = pd.read_csv(path)\n",
    "        n_users = tp['uid'].max() + 1\n",
    "\n",
    "        rows, cols = tp['uid'], tp['sid']\n",
    "        #compressed sparse row matrix로 변환하기 (희소행렬을 다른식으로 변환하여 저장하는 방법)\n",
    "        data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                                 (rows, cols)), dtype='float64',\n",
    "                                 shape=(n_users, self.n_items))\n",
    "        return data\n",
    "    \n",
    "    def _load_tr_te_data(self, datatype='test'):\n",
    "        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n",
    "        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n",
    "\n",
    "        tp_tr = pd.read_csv(tr_path)\n",
    "        tp_te = pd.read_csv(te_path)\n",
    "\n",
    "        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_tr, is_VAE=False):\n",
    "    model.eval()\n",
    "    global update_count\n",
    "    items = []\n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(data_tr.shape[0]):\n",
    "            data = data_tr[start_idx]\n",
    "            data_tensor = naive_sparse2tensor(data).to(device)            \n",
    "            # Multi-VAE\n",
    "            if is_VAE :        \n",
    "                recon_batch, mu, logvar = model(data_tensor)\n",
    "            # Multi-DAE\n",
    "            else:\n",
    "                recon_batch = model(data_tensor)\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            recon_batch[data.nonzero()] = -np.inf\n",
    "            \n",
    "            for rec in recon_batch:\n",
    "                up = np.argpartition(rec, -10)[-10:].tolist()\n",
    "                items.extend(up)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader():\n",
    "    '''\n",
    "    Load Movielens dataset\n",
    "    '''\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.pro_dir = os.path.join(path, 'pro_sg')\n",
    "        #error 설정\n",
    "        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n",
    "        # load_n_items 를 통해 이전에 저장해뒀던 아이템의 랜덤 순서 불러옴\n",
    "        self.n_items = self.load_n_items()\n",
    "    \n",
    "    def load_data(self, datatype='train'):\n",
    "        if datatype == 'train':\n",
    "            return self._load_train_data()\n",
    "        elif datatype == 'validation':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        elif datatype == 'test':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        elif datatype == 'sub':\n",
    "            return self._load_train_data(datatype)\n",
    "        else:\n",
    "            raise ValueError(\"datatype should be in [train, validation, test, submission]\")\n",
    "    \n",
    "    # self.n_items 에 이전에 저장해뒀던 아이템의 랜덤순서 가져다주는 함수\n",
    "    def load_n_items(self):\n",
    "        unique_sid = list()\n",
    "        with open(os.path.join(self.pro_dir, 'unique_sub_sid.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                unique_sid.append(line.strip())\n",
    "        n_items = len(unique_sid)\n",
    "        return n_items\n",
    "    \n",
    "    def _load_train_data(self, datatype = 'train'):\n",
    "        path = os.path.join(self.pro_dir, f'{datatype}.csv')\n",
    "        \n",
    "        tp = pd.read_csv(path)\n",
    "        n_users = tp['uid'].max() + 1\n",
    "\n",
    "        rows, cols = tp['uid'], tp['sid']\n",
    "        #compressed sparse row matrix로 변환하기 (희소행렬을 다른식으로 변환하여 저장하는 방법)\n",
    "        data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                                 (rows, cols)), dtype='float64',\n",
    "                                 shape=(n_users, self.n_items))\n",
    "        return data\n",
    "    \n",
    "    def _load_tr_te_data(self, datatype='test'):\n",
    "        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n",
    "        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n",
    "\n",
    "        tp_tr = pd.read_csv(tr_path)\n",
    "        tp_te = pd.read_csv(te_path)\n",
    "\n",
    "        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#이미 완성된 MultiDAE(denoising auto encoder)의 코드를 참고하여 그 아래 MultiVAE의 코드를 완성해보세요!\n",
    "class MultiDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
    "        super(MultiDAE, self).__init__()\n",
    "        #p_dims, q_dims 는 input, output dimension 리스트\n",
    "        #p_dims = [200, 600, 6807]\n",
    "        self.p_dims = p_dims\n",
    "        #q_dims\n",
    "        if q_dims:\n",
    "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        # q_dims 없으면 p_dims 순서 뒤집어서 사용\n",
    "        else:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        # 항목이 5개가 되게 함\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        # nn.Sequential 과 비슷한함수로, Module 여러개 담아놓는 역할\n",
    "        # nn.Linear(6807, 600), nn.Linear(600,200),nn.Linear(200, 600),nn.Linear(600,6807)\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        #input 정규화 (이유 : 학습 속도 높이고, Local optimum에 빠지게 하지 않기 위해)\n",
    "        #input dropout 으로 몇가닥 끊기(과적합 방지)\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "        #nn.Module에 저장해 뒀던 Linear 함수 적용\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = layer(h)\n",
    "            # 마지막 항에서는 tanh로 activation function 적용\n",
    "            if i != len(self.layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        # 가중치 초기화 하는 함수 \n",
    "        for layer in self.layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            # 가중치 함수 초기화 (평균=0 , 표준편차 = std)\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "\n",
    "\n",
    "def loss_function_dae(recon_x, x):\n",
    "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    return BCE\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "# 다양한 VAE의 코드를 다음 코드를 확인한 뒤에, 아래코드에 맞춰서 직접 작성해보는 연습을 해보세요!\n",
    "# https://github.com/AntixK/PyTorch-VAE\n",
    "class MultiVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-VAE.\n",
    "\n",
    "    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        # init 부분은 Multi DAE 와 동일\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims:\n",
    "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        else:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "\n",
    "        # Last dimension of q- network is for mean and variance\n",
    "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
    "        # encoder 용 : q_layers는 p_dims 뒤집고 마지막항 한번더 연산추가한 Linear layer 들의 결합\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
    "        # decoder 용 : p_layer는 p_dims 그대로 사용한 Linear layer 들의 결합으로\n",
    "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "    \n",
    "    # 인풋 -> 인코더 ->  파라미터 재정비 -> 디코더 -> 아웃풋 + 인코더 결과물(mu, logvar)\n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        h = self.decode(z)\n",
    "        return h, mu, logvar\n",
    "    \n",
    "    def encode(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "        #인코더에서는 MultiDAE 처럼 linear layer 돌림\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                # mu : 평균\n",
    "                # logvar : log 분산 (표준편차가 음수가 되지 않기 위한 연산)\n",
    "                # 처음 값들은 평균(mu)로 보내고 나머지 값들은 분산으로 보냄\n",
    "                # h 는 [항목수, linear 로 변환된 dim]\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "                # 이후 reparameterize 에서 연산처리함\n",
    "        return mu, logvar\n",
    "\n",
    "    # training 과정에서 역전파를 수행할 수 있도록 재매개변수화 함수를 따로 생성했다고 함.\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # 학습중일 때는 평균 중심으로 분산 흩뿌려서 제출\n",
    "        if self.training:\n",
    "            #logvar로 표준편차 계산\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            # std를 정규분포 값으로 초기화한 eps\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        # 아닐 때는 그냥 평균값 배출\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "\n",
    "\n",
    "\n",
    "def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n",
    "    # Loss function은 BCE와 KLD 사용\n",
    "    # KL annealing 을 통해 Regularization 부여\n",
    "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "    # anneal 값을 0에서부터 특정 값까지 선형적으로 증가시켜 \n",
    "    # 학습 초기에 reconstruction term을 강조하여 보다 효율적인 학습 도모함.\n",
    "    return BCE + anneal * KLD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load('MultiDAE.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 각종 파라미터 세팅\n",
    "parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n",
    "\n",
    "\n",
    "parser.add_argument('--data', type=str, default='',\n",
    "                    help='Movielens dataset location')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--wd', type=float, default=0.00,\n",
    "                    help='weight decay coefficient')\n",
    "parser.add_argument('--batch_size', type=int, default=500,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=20,\n",
    "                    help='upper epoch limit')\n",
    "parser.add_argument('--total_anneal_steps', type=int, default=200000,\n",
    "                    help='the total number of gradient updates for annealing')\n",
    "parser.add_argument('--anneal_cap', type=float, default=0.2,\n",
    "                    help='largest annealing parameter')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA')\n",
    "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
    "                    help='report interval')\n",
    "parser.add_argument('--save', type=str, default='model.pt',\n",
    "                    help='path to save the final model')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Set the random seed manually for reproductibility.\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(args.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = loader.load_data('sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "user2rec_list = predict(model, sub_data[user2id[\"5c944530817bf510af65740e\"]], is_VAE=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2item = pd.read_csv(\"id2item.csv\")\n",
    "id2user = pd.read_csv(\"id2user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2id = id2user.set_index('2').to_dict()['1']\n",
    "id2user = id2user.set_index('1').to_dict()['2']\n",
    "id2item = id2item.set_index('1').to_dict()['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2rec_list = [id2item[x] for x in user2rec_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pred() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/project/backend/app/realmodel.ipynb 셀 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B27.96.130.127/opt/ml/input/project/backend/app/realmodel.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmultivae\u001b[39;00m \u001b[39mimport\u001b[39;00m multivae_model\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B27.96.130.127/opt/ml/input/project/backend/app/realmodel.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m aa \u001b[39m=\u001b[39m multivae_model\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B27.96.130.127/opt/ml/input/project/backend/app/realmodel.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m aa\u001b[39m.\u001b[39;49mpred()\n",
      "\u001b[0;31mTypeError\u001b[0m: pred() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "from multivae import multivae_model\n",
    "aa = multivae_model\n",
    "aa.pred()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
